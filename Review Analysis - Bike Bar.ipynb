{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Bar\n",
    "The Bike Bar Group was made up of three companies. There was about 1,140 reviews in this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "\n",
    "working_dir = \"C:\\\\Users\\\\Mary Makris\\\\Documents\\\\Applied Data Analytics\\\\Projects\\\\TOMIS\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize list to store labeled reviews in\n",
    "labeled_reviews = list()\n",
    "\n",
    "#open file of all the reviews, split it on a comma\n",
    "with open (working_dir + 'booze_cruise.csv', 'r', encoding=\"UTF-8\") as xfile:                                        \n",
    "    splitline = csv.reader(xfile, delimiter = \",\")\n",
    "    next(splitline)\n",
    "    #for each line, join the title and the content, and then label them\n",
    "    for line in splitline:\n",
    "        joinline = line[0] + \" \" + line[3]\n",
    "        #label reviews with 4 or 5 stars \"Good\" and 1-3 stars \"Bad\" and put them in the labeled_reviews list\n",
    "        if line[2] == \"50\" or line[2] == \"40\":\n",
    "            labeled_reviews.append((joinline, 'Good'))\n",
    "        else:\n",
    "            labeled_reviews.append((joinline, 'Bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_reviews[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle all the reviews up in case they are in some type of order\n",
    "random.shuffle(labeled_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_features(review):\n",
    "    '''This function should take in a review and return \n",
    "    a dictionary value with the name of the feature as the key and \n",
    "    the value as the feature value'''\n",
    "     \n",
    "    split_review = review.split(\" \")                            ### split the list of words\n",
    "    lowcase_review = [thing.lower() for thing in split_review]     ### make all the descriptions lowercase\n",
    "    clean_review = [re.sub(r'[^\\w\\s]','',word) for word in lowcase_review]  ## fix punctuation\n",
    "    print(clean_review)                                                                   \n",
    "    ret_val = {}                                                   ###store words in a dictionary\n",
    "    for word in clean_review:\n",
    "        ret_val[word] = True\n",
    "    return(ret_val)\n",
    "\n",
    "#Test the function\n",
    "review_features(\"Is this working correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run each review through function and store the results in a variable called feature sets\n",
    "featuresets = [(review_features(review), rating) for (review, rating) in labeled_reviews]   \n",
    "#Split the reviews into a training set and a test set\n",
    "train_set, test_set = featuresets[250:], featuresets[:250]    \n",
    "#run the training set through the Naive Bayes classifier to train it\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at how accurate the classifier was when analyzing the test set of reviews that were left out\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look at the most informative features determined by the classifer\n",
    "classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize a list to store all the reviews\n",
    "all_reviews = []\n",
    "\n",
    "#split each review into individual words, and store the words in the all_reviews list\n",
    "for review, label in labeled_reviews :\n",
    "    words = review.split() \n",
    "    for word in words :\n",
    "        all_reviews.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##tokenize each word in the list of reviews\n",
    "all_reviews = nltk.word_tokenize(\" \".join(all_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##According to the NLTK documentation nltk.text is wrapper around the tokens that allows you to then run functions like \n",
    "##concordance. So I run it on the now tokenized words in all the reviews and store with the same name as before\n",
    "all_reviews = nltk.Text(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at the context surrounding each word to get more information about what the review entailed\n",
    "all_reviews.concordance(\"informativefeatureword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the top 50 features and the context surrounding them, I pulled the 5 to 10 that I felt \n",
    "would be most useful and informative from a business perspective that TOMIS could use in their work with clients. \n",
    "Likely because of the low number of negative reviews, the classifier had low accuracy rates and the context shows words \n",
    "in reviews that are positive. \n",
    "\n",
    "### Top Informative Features & Probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEIGHBORHOOD:\n",
    "(Bad : Good   =     65.5 : 1.0)    \n",
    "\n",
    "the Midtown Route and loved the neighborhood and bars we stopped in . Everybo\n",
    "fun pedaling around , seeing the neighborhood , ... Unique , fun experience Su\n",
    "und in circles in one particular neighborhood . For $ 40 a person , ... A tota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATHROOM:\n",
    "(Bad : Good   =     65.5 : 1.0)\n",
    "\n",
    "un way to see the city . You get a bathroom break half way through . They also\n",
    "ng is rude and they do n't offer a bathroom which ... Bachelorette Party ! Rya\n",
    " instructions and 15 minutes for a bathroom break . The girls driving and bart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOOD:\n",
    "(Bad : Good   =     65.5 : 1.0)\n",
    "\n",
    "azing personality and really set the mood for this awesome experience . He als\n",
    " our driver was not in the same good mood as we were . Everyone has ... We wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEGS:\n",
    "(Bad : Good   =     65.5 : 1.0)\n",
    "\n",
    "the experience even better . Get ur legs ready tho , pedaling that bike is n'\n",
    "ainly helps move it along , but your legs will get tired - especially if you h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINUTES:\n",
    "(Bad : Good   =     65.5 : 1.0)\n",
    "\n",
    "xpect but it was a blast . after 90 minutes I did not want to get off the bike \n",
    " . My wife and I were running a few minutes late and he ( and the other people \n",
    ") were kind enough to wait a couple minutes for us . They were all awesome ... \n",
    " would see this attraction every 20 minutes drive by . All the people on this p\n",
    "our and a half but that included 15 minutes of instructions and 15 minutes for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
